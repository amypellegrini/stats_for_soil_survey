---
title: "Modeling Frameworks"
author: "Dylan Beaudette"
date: "`r Sys.Date()`"
output:
  html_document:
    keep_md: no
    number_sections: yes
    toc: no
    toc_depth: 3
    toc_float:
      collapsed: true
      smooth_scroll: false
---

The Stats II class is a ways off, but the following article is something we might want to present to the group. It is an approachable, practical description of two very different modeling frameworks. This kind of meta-discussion would (I think) help folks select among possible frameworks based on the complexity of the problem, the available data, and the relative position on the inference--prediction scale.


http://www.fharrell.com/post/stat-ml2/


The attached figure goes along with a bit of conversation I had (below) with some of my colleagues, on the topic of modeling soil temperature regime using a variety of frameworks. Given the nature of the setting (MLRAs 17, 18, 22A, 22B), we selected a modeling framework that generated reasonable predictions and resulted in an interpretable model.

If folks are interested, the source data might be a nice demonstration of multiple linear regression (MAST) and multinomial logistic regression (STR). The source data, predictor variables, and resulting models are fairly simple. I would be happy to package-up the source data and associated modeling code.


==== 
Excerpt from Recent Conversation
====

![](str_vs_elev-model-comparison.png)

Essentially, each framework (MLR, regression trees, randomForest, etc.) is useful for different tasks but thinking about the most appropriate framework ahead of time is time well spent. Predictions aren't the same as science or understanding. Sometimes we need the former, sometimes we need the latter and sometimes we need both.

The attached is a modified version of a figure from our discussion on Wednesday. The x-axis is elevation, in most cases the dominant driver of soil temperature and soil temperature regime in this area. The y-axis is conditional probability of several STR.

The top panel represents the smooth surface fit by multinomial logistic regression. These smooth surfaces lend to testable interpretations such as "the transition between STR per 1,000' of elevation gain follows XXX". This is far more useful when the model includes other factors such as annual beam radiance and the effect of cold air drainages. Absolute accuracy is sacrificed for a general (e.g. continuous over predictors) representation of the system that can support inference. Another example, "at elevation XXX, what is the average effect of moving from a south-facing slope to a north-facing slope?".

The second panel down represents the hard thresholds generated by an algorithm from the tree-based classification framework (e.g. recursive partitioning trees via rpart). Accuracy is about the same as the MLR approach and the hard breaks can be interpreted as "reasonable" cut points or thresholds that may have links to physical processes. Note that the cut points identified by this framework are very close to the 50% probability cross-over points in the MLR panel. The result is a (potentially) pragmatic partitioning of reality that can support decisions but not inference (e.g. "rate of change in Pr(STR) vs. 1000' elevation gain").

The third panel down represents the nearly-exact (over?) fitting of STR probabilities generated by the random forest framework. This approach builds thousands of classification trees and (roughly) averages them together. The results are incredible (unbelievable?) within-training-set accuracy (99% here) at the expense of an interpretable model. That isn't always a problem: sometimes predictions are all that we have time for. That said, this framework requires a 100x larger training sample (vs. MLR) and an independent validation data set before it can be trusted on new data.

=====
