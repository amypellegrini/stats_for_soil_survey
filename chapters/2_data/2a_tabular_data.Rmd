---
title: Chapter 2 - Tabular data we use
author: Jay Skovlin and D.E. Beaudette
date: "Friday, February 9, 2016"
output: html_document
html_document:
    keep_md: yes
---

```{r setup, echo=FALSE, results='hide', warning=FALSE}
library(knitr, quietly=TRUE)
#library(sp, quietly=TRUE)
#library(maps, quietly=TRUE)
# library(printr, quietly=TRUE)
opts_chunk$set(message=FALSE, warning=FALSE, background='#F7F7F7', fig.align='center', fig.retina=1, dev='png', tidy=FALSE, verbose=FALSE)
options(width=100, stringsAsFactors=FALSE)
```


```{r setup1, echo=FALSE, results='hide', warning=FALSE}
# blocked for now - remove later went I post to github!!!
#![Statistics for pedologists course banner image](figure/logo.jpg)  
```

#Getting acquainted with the soilDB package
##Objectives:
- Use the soilDB package to load NASIS pedon data into R
- Examine the data and understand its structure
- Learn ways to work with and inspect pedon data in R

##Steps:
- Establish an ODBC connection to view NASIS data in R
- Understand the basic structure of pedon data stored in a Soil Profile Collection (SPC)
-	Learn about the checks run by the fetch functions when pulling data into R
-	View a set of pedon data from a selected set in NASIS in R
-	Learn basic commands for inspecting objects and data types
- Learn basic checks that you can do to filter and inspect the consistency of a pedon dataset
-	Not finding the data you need? Joining additional data to an SPC via extended data functions

##Contents:

 * [2.1 ODBC Connection to NASIS](#ODBC)
 * [2.2 fetch functions and data checks](#fetch) 
 * [2.3 Soil Profile Collection (SPC) object](#SPC)
 * [2.4 Viewing pedon data](#view) 
 * [2.5 Working with SPC data in R](#basicR) 
 * [2.6 Consistency checking pedon data in R](#check) 
 * [2.7 Preparing other data sources for R](#data)
 * [2.8 References](#ref)
 
###R fundamentals
 
####Data types used in R
 
One of the most versatile things about R is that there are many ways manipulate and work with data.  Below are examples of how to create and reference information in several data types that are commonly used in working with soil data.
 
####Vectors
 
```{r datatype1, eval=TRUE}
 # numeric vector example - clay %
 a <- c(10,12,15,26,30)
 # 'c()' is the concatenate function
 # values are concatenated into an object we've called 'a' by assigning the concatenate result to 'a' using '<-' or '='
 # print the values of 'a' by typing it into the R console followed by enter
 a
 
 # character vector - taxonomic subgroup
 b <- c("typic haplocryepts","andic haplocryepts","typic dystrocryepts")  
 b
 
 #logical vector - SPC diagnostic feature presence/absence
 c <- c(TRUE,FALSE,TRUE) 
 c
 
 # Referencing elements of a vector
 # 2nd and 4th elements of vector 'a' from above
 a
 a[c(2,4)] 
 # 1st and 3rd elements of vector 'b' from above
 b
 b[c(1,3)]

```

So what's the deal with the square bracket notation?  

 
####Dataframes
 
```{r datatype2, eval=TRUE}
  # Take our two character and logical vectors we created above and convert them into a more useful dataframe.
  # Dataframes are a common format that is easily crossed over to from spreadsheet format where we are 
  # used to thinking in terms of rows and columns of data.
  # we'll use the data.frame() function to glue these two vectors together into object 'd'
  d <- data.frame(b, c)
  d
 
  # we can see that it worked but the vector names are not very informative
  # here are a couple of useful functions for working with column names
  # we can use 'names()' and 'c()' to rename the vectors within the dataframe
  names(d) <- c('tax_subgroup', 'andic.soil.properties')
  d
```

####Referencing within dataframes
Notice in dataframe 'd' that each row has an index number in front of it.  using the square brackets notation we can reference any part of a dataframe - rows or columns or specific row and column selections.  Here are some examples:
  
```{r datatype2a, eval=TRUE}
  # format: dataframe_name[rows, columns]
  d[1, ] # first row of dataframe
  d[, 1] # first column of dataframe
  d[2, 2] # second row, second column
  
  # In dataframes we can also use the '$' symbol to reference vector columns within a specific dataframe object
  d$tax_subgroup
  
  # Other useful functions for checking objects and working with dataframes
  # the 'str()' function will show you the structure of an object and the data types of the vectors within it
  str(d)
  # 'class()' will tell you the object type or data type
  class(d)
  # use 'colnames()' to get a vector of column names from a dataframe
  colnames(d)
  
  # building on what we've learned above, we can use the square bracket notation on a dataframe to re-order columns
  d <- d[ , c('andic.soil.properties', 'tax_subgroup')]
  d
  
``` 

####Other less commonly used data types

 - **Lists**
 ```{r datatype3, eval=TRUE}
 
 
 ```
 
 - **Matrices**
 ```{r datatype4, eval=TRUE}
 
 
 ```
 
 - **Arrays**
 ```{r datatype5, eval=TRUE}
 
 
 ```
 
 - **Factors**
 ```{r datatype6, eval=TRUE}
 
 
 ```
 
###<a id="ODBC")></a>2.1  Using the soilDB package to load NASIS pedon data into R 
 
 **First step - set up an Open Database Connectivity (ODBC) connection to NASIS on your computer**  

Data from a selected set of NASIS may be used as described in this job aid [**How to Create an ODBC Connection and Setup SoilDB for Use with R**](http://www.nrcs.usda.gov/wps/PA_NRCSConsumption/download?cid=stelprdb1237479&ext=pdf).

 **Query and load some pedon data into your NASIS selected set**
 show screen shots of the results returned.
 may need to re-organize the order of the sections/material presented here....to make it flow logically.    
 


####What is the soilDB package and what does it do?
The soilDB package is an R package that is designed for extracting and importing soil data from NASIS.  The package has a series of different fetch functions which pull data via Structured Query Language (SQL) queries of data in a NASIS selected set.  Scripting within the fetch functions then does some basic data checks and assembles the data into site-level and horizon-level data structures within a custom R object called a `Soil Profile Collection (SPC)` that is specifically designed to accommodate the basic structure of soil data - site data with corresponding horizon data.  It is important to mention that this process is not comprehensive, soilDB does not pull all of the data for every table out of NASIS.  In addition, various complexities of the NASIS data structure have been simplified in creating the SPC object that results from a function like `fetchNASIS()`.  Higher level functions like the `fetchNASIS()` bundle a series of lower level functions which get specific parts of the data structure.  

One-to-many relationships are flattened where possible by soilDB fetch functions to aggregate the data to one site record.  Additional data that may have a one-to-many relationship to a site or pedon can be gathered from the data via `get_extended_data` functions.

The following is from another tutorial.....in the aqp package.
This is a very basic introduction to the `SoilProfileCollection` class object defined in the `aqp` package for **R**. The `SoilProfileCollection` class was designed to simplify the process of working with collections of data associated with soil profiles: site-level data, horizon-level data, spatial data, diagnostic horizon data, metadata, etc. Examples listed below are meant to be copied/pasted from this document and interactively run within **R**. Comments (green text) briefly describe what the code in each line does. This document assumes a basic level of proficiency with **R** which can be gained by reviewing some of the material in [tutorials like this](http://cran.r-project.org/doc/contrib/Verzani-SimpleR.pdf). Further documentation on objects and functions from the `aqp` package can be accessed by typing `help(aqp)` (or more generally, `?function_name`) at the **R** console.

**In short.....it greatly simplifies the process of getting data from NASIS into R for further analysis.**

```{r structure_diagram_a, echo=FALSE, results='hide', warning=FALSE}
# get script from home desktop......modify it to work for this little figure  
library(diagram, quietly=TRUE)
par(mar = c(0, 0, 0, 0), mfrow = c(2, 2))

# simple diagram of the pedon data structure
names <- c("Site", "Siteobs", "Pedon", "Horizon")
M <- matrix(nrow = 4, ncol = 4, byrow = TRUE, data = 0)
M[4, 3] <- M[3, 2] <- M[2, 1] <- ""
pos <- cbind (c(1, 1, 1, 1))
plotmat(M, pos = pos, name = names, lwd = 1, box.lwd = 2, cex.txt = 0.8, box.size = 0.1, box.type = "square", box.prop = 0.4, mx=-0.2,)

# parallel simplified SPC structure
names <- c("Site-level", "Horizon-level")
M <- matrix(nrow = 2, ncol = 2, byrow = TRUE, data = 0)
 M[2, 1] <- ""
#pos <- cbind (c(2, 2))
plotmat(M, pos = c(1, 1), name = names, lwd = 1, box.lwd = 2, cex.txt = 0.8, box.size = 0.14, box.type = "square", box.prop = 0.75, mx=0.3, my=-0.1, add=TRUE)

# add arrows to the diagram
#arrow()
```

###Additional exploratory fetch functions in the soilDB package

- **fetchNASISLabData()**
  - KSSL laboratory pedon/horizon layer data from a local NASIS database.
- **fetchKSSL()**
  - Get KSSL data via BBOX, MLRA, or series name query, from the SoilWeb system.
- **fetchOSD()**
  - fetches a limited subset of horizon and site-level attributes for named soil series, from the SoilWeb system.
- **fetchRaCA()**
  - et Rapid Carbon Assessment (RaCA) data via state, geographic bounding-box, RaCA site ID, or series query from the SoilWeb system.
- **fetchSCAN()**
  - Query soil/climate data from USDA-NRCS SCAN Stations (experimental)
- **fetchHenry()**
  - Download Data from the Henry Mount Soil Climate Database (experimental)
- **fetchPedonPC()**
  - Fetch commonly used site/horizon data from a PedonPC v.5 database.

 
###<a id="fetch")></a>2.2  Checks run by the fetch functions when pulling data into R 

When loading pedons with the fetchNASIS() function the following data checks are performed:

- **presence of multiple map datums:** results reported to the user and the data are not modified

- **inconsistent horizon boundaries:** pedons with inconsistent horizon boundaries are not loaded.  In most cases this occurs when the bottom depth of a horizon is not the same as the upper depth of the next lower horizon.

```{r example_a, echo=FALSE, results='show', warning=FALSE}
top <- as.integer(c(0,38,56,135))
bot <- as.integer(c(30,56,135,152))
hzname <- c('A', 'Bt1', 'Bt2', 'Bk')
d <- data.frame(hzname, top, bot)
d
```
Bottom depth of the A horizon and the upper depth of the Bt1 horizons should be the same - either be 30 or 38 cm?  Need to determine which to correct this issue.

- **missing lower horizon depths:** offending horizons are fixed by replacing the missing bottom depth with the top depth + 2cm

- **sites missing pedon records:** data without corresponding horizons are not loaded


####How can we find the site ID's where these errors occur so that we can to fix them in NASIS?
Should errors in the pedon data be detected when loading data using fetchNASIS() you can use the following 'get' functions to trace them back to the records in NASIS:

- **get('sites.missing.pedons', envir=soilDB.env)**
  - returns user site ID's for sites missing pedons
  
- **get('dup.pedon.ids', envir=soilDB.env)**
  - returns pedon ID's for sites with duplicate pedon ID's
  
- **get('bad.pedon.ids', envir=soilDB.env)**
    - returns user pedon ID's for pedons with inconsistent horizon depths - modify to return site id's as well.
    


For more information on the design of soilDB functions use the following link to the soilDB documentation - [**Introduction to soilDB**](https://r-forge.r-project.org/scm/viewvc.php/%2acheckout%2a/docs/soilDB/soilDB-Intro.html?root=aqp)


###<a id="SPC")></a>2.3  The structure of pedon data stored in the Soil Profile Collection (SPC) object

#### The `Gopheridge` Sample Dataset
The `gopheridge` sample dataset is very similar to the type of data returned from `fetchNASIS()`. The following demonstration is intended to show the structure of the Soil Profile Collection (SPC) object that is returned by 'fetchNASIS()'. 

Before proceeding it may be helpful to review the `aqp` manual pages: `library(aqp) ; help(aqp)`, or the [**SoilProfileCollection object introduction**](https://r-forge.r-project.org/scm/viewvc.php/*checkout*/docs/aqp/aqp-intro.html?root=aqp).  This tutorial provides an excellent overview of how the SPC object is constructed.

Open R, and setup the environment by loading packages and the Gopheridge sample dataset.

```{r gopheridge_a}
library(soilDB)

# load example dataset
data(gopheridge)

# what kind of object is this?
class(gopheridge)

# let's take a look at the fields at the site and horizon levels within the SPC
names(gopheridge@site)
names(gopheridge@horizons)

# look at the first 2 lines of the data
head(gopheridge, 2)
```
###Follow along with your own data

```{r owndata_a, results='hide'}
library(soilDB)
library(aqp)

# load data from a NASIS selected set
f <- fetchNASIS()

# what kind of object is this?
class(f)

# let's take a look at the fields at the site and horizon levels within the SPC
names(f@site)
names(f@horizons)

# look at the first 2 lines of the data
head(f, 2)
```

###Question:
####How can we find out how many site and horizon records we have in the data we've just loaded?
uoᴉʇɔunɟ ()ɹʇs ǝɥʇ ǝsn




###<a id="view")></a>2.4  Viewing pedon locations
####Plotting geographic data directly in R

 - **Quick check:** Does the data roughly plot where you would expect it to?
 
Plotting the data directly as an R graphic can give you some idea of how the data look spatially and whether their distribution approximates what you would expect to see.  Typos in coordinates are relatively common when they are manually entered and viewing the data spatially is a very quick way to see points that plot way outside of the geographic area of interest and clearly have some kind of error.

- TODO: include code to subset to exclude points with location errors? 


```{r gopheridge_b}
# plot the locations of the gopherridge pedons within R
# Steps:
# 1) subset to a new data frame
# 2) create a spatial points data frame (SPDF)
# 3) plot the data

# load libraries
library(sp)
library(maps)

# subset standard WGS84 decimal degree coordinates from the gopheridge SPC by specifying column names
gopher.locations <- site(gopheridge)[, c('site_id', 'x_std', 'y_std')]

# initialize coordinates in an SPDF
coordinates(gopher.locations) <- ~ x_std + y_std

# set plot margins
par(mar=c(0,0,0,0))

# plot county boundaries for all of CA
map('county', 'california', fill = FALSE)
# add plot of pedon data locations
plot(gopher.locations, add = TRUE)

# plot again but zoom in by setting xlim, ylim extents
map('county', 'California', xlim=c(-122.25, -119.75), ylim=c(37, 38.5))

# add plot of pedon data locations
plot(gopher.locations, add = TRUE)
box()

```

####Displaying pedon data in Google Earth
Google Earth is a powerful data viewer for point data.  Geographic data in Google Earth is displayed using the Keyhole Markup Language (KML) format.  Using the [plotKML](https://cran.r-project.org/web/packages/plotKML/plotKML.pdf) package we can easily create a KML file for inspection and viewing in Google Earth.  See the related material in this tutorial [Export Pedons to Google Earth](https://r-forge.r-project.org/scm/viewvc.php/*checkout*/docs/soilDB/export-points-from-NASIS-to-Google-Earth.html?root=aqp). 

####Exporting pedon data to an ESRI shapefile
Another way we could view the data is to export a shapefile from R.  Further information on how to do this can be found in this tutorial [Export Pedons to Shapefile](https://r-forge.r-project.org/scm/viewvc.php/*checkout*/docs/soilDB/export-points-from-NASIS.html?root=aqp).


###<a id="basicR")></a>2.5  Working with SPC data in R

####Summarizing data

Now that we've loaded some data, let's look at additional ways that you can summarize data elements and filter the SPC to specific sites of interest. The `table()` function is very useful for quick summary operations.  This function can be combined with other functions such as `sort()` and `is.na()` or `!is.na()` (is not NA). Follow along with your own data.

```{r owndata_b, results='hide'}
# summarize which soil taxa we have loaded
table(f$taxonname)
# sort results in descending order
sort(table(f$taxonname), decreasing=TRUE)

# could do the same thing for taxonomic subgroups or any column of the SPC at the site or horizon levels
table(f$tax_subgroup)
sort(table(f$tax_subgroup), decreasing=TRUE)

# table() is also useful when testing for null data using IS NA, is.na() or IS NOT NA, !is.na()
table(is.na(f$tax_subgroup))
table(!is.na(f$tax_subgroup))

# it can also be applied to horizon level columns in the SPC
  sort(table(f$texture), decreasing=TRUE)
```

####Filtering data using pattern matching

A collection of soil profiles or an SPC can be subset using a variety of methods and then the results can be placed into another SPC. The following examples use the `grep()` function to pattern match within the data and create an index of the SPC for records that match the specified pattern within that column and then use that index to filter to specific sites and their corresponding profiles.

This process can be applied to many different columns in the SPC based on how you need to filter the data.  This example pattern matches on the `tax_subgroup` column, but another useful application might be to pattern match on geomorphic or parent material information.

The soilDB package flattens the nested table structure of parent material and geomorphic description within NASIS into single strings per site-level record.  Pattern matching can be used to select profiles based on parts of these strings. 

```{r owndata_c, results='show'} 
sort(table(f$landform.string), decreasing=TRUE)
```

Notice below that the `grep()` also has an ***invert option***, which is specified as either TRUE or FALSE (the default when unspecified is FALSE).  This option is very useful for excluding the results of the pattern matching process by inverting the selection.

```{r owndata_d, results='hide'}
# say we wanted to look at what the variation of particle size classes are within a specific subgroup?
# use of grep() to filter and create an index, then apply that index to the SPC 
# and create a new SPC called 'f1' using the square bracket notation
idx <- grep('lithic', f$tax_subgroup, invert=FALSE)
# save this subset of 'lithic' soils for later use  
f1 <- f[idx, ]
# or use the index directly to summarize a field
sort(table(f$part_size_class[idx]), decreasing=TRUE)
```
Let's do a quick graphical check that we've selected the 'lithic*' profiles by plotting them in R using the AQP package `plot()` function.

```{r owndata_e, results='show'}
# plot the first 10 profiles of the 'f1' subset
plot(f1[1:10, ], label='site_id')
```

####Filtering data by specifying a criteria using the `which()`

Another method of subsetting a collection of soil profiles is to specify a criteria using the `which()` function. The following examples use the `which()` and `grep()` functions to reference the indexing of the SPC to create subsets and to filter to specific sites or their corresponding profiles.

```{r owndata_f, results='show'}
# say we wanted to look at what the variation of particle size classes are within a specific subgroup?
# first: use grep to pattern match the tax_subgroup field for the string 'aqu'
idx <- grep('aqu', f$tax_subgroup)
# save this subset
f1 <- f[idx, ]
# check taxonomic range of particle size classes in the data
sort(table(f1$tax_subgroup), decreasing=TRUE)
sort(table(f1$part_size_class), decreasing=TRUE)

# then further query the subset for only those profiles with PSC of 'sandy-skeletal'
idx <- which(f1$part_size_class == 'sandy-skeletal')
# save this subset
f2 <- f1[idx, ]
# or use the index directly to summarize a field
sort(table(f2$part_size_class), decreasing=TRUE)
# plot  profiles 1 thru 10
plot(f1[1:10, ], label='site_id')
```

###Extracting Site and Horizon data

Soil Profile Collections are designed to be dismantled in order to work with either site or horizon data more easily.  Within the SPC there is a slot for site-level data and a slot for horizon-level data.  We can reference these slots using the `site()` and `horizons()` functions within the AQP package.  These getter functions will extract all the site or horizon variables as a dataframe for further use.  

```{r owndata_g, results='show'}
# extract site data from SPC into dataframe 's'
s <- site(f)
names(s)
# extract horizon data from SPC into dataframe 'h'
h <- horizons(f)
names(h)
```
We can also use these functions in referencing the data within an SPC to specify that we want to look specifically in the site or horizon data. 

###Review of data checks run by `fetchNASIS()`
Now that we've loaded some data and learned a little about how to filter data in the SPC, let's quickly review some of the `get()` functions used to track data issues detected in the process of loading back to records in our selected set.

```{r owndata_a1, results='hide'}
# use each one of these to return a vector of the pedons where errors were detected
#get('sites.missing.pedons', envir=soilDB.env)
#get('dup.pedon.ids', envir=soilDB.env)
#get('bad.pedon.ids', envir=soilDB.env)
# example of pedon_id's returned
#[1] "2011MT0810001" "2011MT0810009" "2011MT00810015" "2011MT0810027" "2011MT0810034"

# How could you then remove these from your SPC?
# assign these 'bad' ids to a vector
get('bad.pedon.ids', envir=soilDB.env)
# since the get() returns the string of bad pedon id's we can use a which() to query pedon id's that don't match the bad id's
idx <- which(horizons(f)$pedon_id != get('bad.pedon.ids', envir=soilDB.env))
f <- f[idx, ]
```
Another useful function is `dput()` which will concatenate a variable converting something like this:\
"2011MT0810001" "2011MT0810009" "2011MT00810015" "2011MT0810027" "2011MT0810034"\
Into this:\
c("2011MT0810001", "2011MT0810009", "2011MT00810015", "2011MT0810027", "2011MT0810034")

###Logical evaluations using `ifelse()`

Often there are operations in which we need to evaluate the site or horizon data and assign some variable using a logic statment.  One way to do this is to use the `ifelse()` function.  The following shows some examples of how to do this.

```{r owndata_h, results='show'}
# assigning a variable using a logical statement
# standard format
#    ifelse(variable == '', then do, else do)
# can also nest these statements
#     ifelse(variable == '', then do...., ifelse(variable == '', then do..., else do....)) 

```

###Custom functions

Functions can bundle a series of operations and then be applied to an SPC using `profileApply()`.  Say we wanted use some pedon data to model the depth to calcium carbonate.  One way to do this would be to look through horizon designations to derive a depth to calcium carbonate using the 'k' suffix designation.  A first step to doing something like this would be to think about outlining the steps involved in the process.  

What steps would be needed to accomplish this task and return an upper depth to carbonates for each site?

 - extract the horizon data for each profile
 - Would we want to remove organic horizons?  Starting our depth to carbonates at the mineral soil surface.
 - iterate through the horizon designations(hzname) pattern matching for 'k'
 - apply the function to each profile via `profileApply()`
 - summarize the data returned by the function to one value per profile
 - join the summarized depth value back to the site data
 
```{r owndata_i, results='show'}
# load library
library(plyr)

f.limy <- function(i) {
  # extract horizons
  h <- horizons(i) 
  # filter O horizons to remove them
  h <- h[grep('O', h$hzname, invert=TRUE), ]  
  # pattern match for 'k' horizon designations in horizon data
  h2 <- h[grep('k', h$hzname, invert=FALSE), ] 
  min_depth <- min(h2$hzdept)
  
  # return data
  return(data.frame(peiid=h2$peiid, phiid=h2$phiid, hzname=h2$hzname, hzdept=h2$hzdept, hzdepb=h2$hzdepb, ph_0_18=h2$phfield, efferv_0_18=h2$effervescence))
}

# apply function to each profile, results are a list of data.frames
l <- profileApply(f, FUN=f.limy, simplify=FALSE)

# convert list into a dataframe
limy <- ldply(l)

# show contents of the limy dataframe
head(limy)

# example of data returned - you can see that we still need to summarize this to get the upper depth from multiple 'Bk' horizons
# notice that a couple of additional variable were return by the function
#     .id  peiid   phiid hzname hzdept hzdepb ph_0_18 efferv_0_18
#1 828198 828198 4268004    Bk1     91    152     8.2     violent
#2 828198 828198 4268003    Bk2    152    182     8.2      strong

# still need to reduce this down to one depth value for each profile
# summarize this dataframe using summarise() in the plyr package
limy1 <- ddply(limy, 'peiid', summarise, depth_to_caco3_cm=min(hzdept))

# since we have peiid in the limy1 dataframe we can easy join it back to site data in the SPC
site(f) <- limy1

# summary of depth to carbonates in the data
table(f$depth_to_caco3_cm)
```

###<a id="check")></a>2.6  Consistency checking pedon data using R
####assumptions:

[Dealing with Troublesome data](https://r-forge.r-project.org/scm/viewvc.php/*checkout*/docs/aqp/dealing-with-bad-data.html?root=aqp)

- some common pit falls of working with pedon data
- consistency in data population is key!
- horizonation issues, etc
- missing data










###<a id="data")></a>2.7  Preparing other data sources for use in R  

When preparing data for statistical analysis, a nicely formatted summary table is not appropriate. The data needs to be basic and compact.  The required configuration will be a comma delimited text file, where columns contain dependent and independent variables and rows contain individual observations of the variables.  Using sand content as an example, you might collect or present your data like this:  

```{r setup3, echo=FALSE, results='hide', warning=FALSE}
# blocked for now - remove later went I post to github!!!
#![R GUI image](figure/ch2_fig1.jpg)  
```

However, for use in R, the data needs to be organized with total sand content as one long column – with headers for organization.  Remove spaces from column headers, and simplify and standardize the coding of categorical variables.  There should be only 1 header row followed by data as noted in this formatted table.  
```{r setup4, echo=FALSE, results='hide', warning=FALSE}
# blocked for now - remove later went I post to github!!!
#![R GUI image](figure/ch2_fig2.jpg)  
```
The same table in a format suitable for use by R  

location,landuse,horizon,depth,sand  
city,crop,A,14,19    
city,crop,B,25,21  
city,pasture,A,10,23    
city,pasture,B,27,34  
city,range,A,15,22  
city,range,B,23,23  
farm,crop,A,12,31  
farm,crop,B,31,35  
farm,pasture,A,17,30  
farm,pasture,B,26,36  
farm,range,A,15,25  
farm,range,B,24,29  
west,crop,A,13,27  
west,crop,B,29,25  
west,pasture,A,11,21  
west,pasture,B,31,26  
west,range,A,14,23  
west,range,B,24,24  

If you copy and paste the comma delimited text, starting with the header line of location, and save it as a text file named “sample_table.txt” in the \ C:/Temp\ folder, you can open R and run these commands by copying text from the boxes and pasting into the R prompt:  

###<a id="refs")></a>2.8  References and useful links

[tutorials like this](http://cran.r-project.org/doc/contrib/Verzani-SimpleR.pdf)












