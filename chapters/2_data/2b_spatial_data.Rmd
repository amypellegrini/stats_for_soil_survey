---
title: "Spatial Data"
author: "Stephen Roecker, Jay Skovlin, Dylan Beaudette, Skye Wills, Tom D'Avello"
date: "`r Sys.Date()`"
output:
  html_document:
    keep_md: no
    number_sections: yes
    toc: no
    toc_depth: 3
    toc_float:
      collapsed: true
      smooth_scroll: false
---

```{r setup, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# setup
library(knitr, quietly=TRUE)
library(printr, quietly=TRUE)
opts_chunk$set(message=FALSE, warning=FALSE, background='#F7F7F7', fig.align='center', fig.retina=2, dev='png', tidy=FALSE, verbose=FALSE, antialias='cleartype', cache=FALSE)

# options for R functions
options(width=100, stringsAsFactors=FALSE)

# captions added to figures
knit_hooks$set(htmlcap = function(before, options, envir) {
  if(!before) {
    paste('<p class="caption" style="font-size:85%; font-style: italic; font-weight: bold;">',options$htmlcap,"</p><hr>",sep="")
    }
    })
```

<hr><br>

# Introduction

Most of us are familiar with spatial data types, sources, and the jargon used to describe interaction with these data. GIS software provides a convenient framework for most of the spatial analysis that we do, however, the combination of statistical routines, advanced graphics, and data access functionality make *R* and ideal environment for soil science. For example, with a couple of lines of *R* code, it is possible to quickly integrate soil morphology (NASIS), lab data (KSSL), map unit polygons (SSURGO), and climate data (PRISM raster files). 

This chapter is a very brief demonstration of several possible ways to process spatial data in R. A much more thorough description can be found in [*Applied Spatial Data Analysis with R*](http://www.asdar-book.org/) (Bivand et al., 2013) or [*Spatial Data Analysis and Modeling with R*](http://rspatial.org/spatial/) (Hijmans, 2016).


## Objectives
 * Gain experience with creating, editing, and exporting spatial data objects in R.
 * Lean the basics of the `sp` classes and functions.
 * Learn the basics of the `raster` classes and functions.
 * Develop a strategy for navigating the many possible spatial data processing methods.
 * Learn how to integrate multiple data sources to create something new.
 

# Spatial Data in R

There are several foundational libraries that extend the basic functionality of the R environment to accommodate the special requirements of spatial data:

 * `sp`: vector / raster storage and processing (memory-bound operations)
 * `raster`: raster access and efficient processing of large files (not memory-bound)
 * `rgdal`: interface to GDAL library for data import/export and coordinate system transformations
 
There are [many, many more packages](https://cran.r-project.org/web/views/Spatial.html) available for working with spatial data, however we only have time to cover the above libraries. 
 

The next couple of sections will require loading these libraries into the R session.
```{r}
library(sp)
library(raster)
library(rgdal)
```


## The `sp` Package

The data structures ("classes") and functions provided by the [`sp`](https://cran.r-project.org/web/packages/sp/index.html) package have served a foundational role in the handling of spatial data in R. Many of the following examples will reference names such as `SpatialPoints`, `SpatialPointsDataFrame`, and `SpatialPolygonsDataFrame`. These are specialized classes, implemented by the `sp` package, that maintain linkages between all of the components of spatial data. For example, a point, line, or polygon feature will typically be associated with:
 
 * coordinate geometry
 * bounding box
 * coordinate reference system
 * attribute table

While it is possible to hand-make `sp` class objects, it is usually faster to import existing raster or vector files from disk. More on this later. For the sake of demonstration we will make a `SpatialPointsDataFrame` object. This is analogous to the point type feature class or shapefile.

```{r}
# create point geometry from coordinates
p <- SpatialPoints(coords = cbind(-97.721210, 40.446068))
# attach attribute table
p <- SpatialPointsDataFrame(p, data=data.frame(id=1, taxonname='alpha'))
# check internal structure
str(p)
```

This is an "S4" object with "slots" (e.g. `@data`) that are used to store various components. Most all S4 objects have specialized functions for getting and setting the contents of the slots. For example, the `bbox()` function is used to get or set the contents of the `@bbox` slot.


There is a convenient shortcut for "upgrading" point data that is stored in a `data.frame`. This is especially useful for preparing NASIS/KSSL data for spatial operations.
```{r}
# make some fake data
d <- data.frame(x=40.446068, y=-97.721210, id=1, taxonname='alpha')
# upgrade to SpatialPointsDataFrame
coordinates(d) <- ~ x + y
# check
class(d)
```

See the [sp gallery](https://edzer.github.io/sp/) and [this vignette](https://cran.r-project.org/web/packages/sp/vignettes/intro_sp.pdf) for a much more detailed description of the `sp` classes.


### Coordinate Reference Systems and `proj4` Syntax

Spatial data aren't all that useful without an accurate description of the coordinate reference system (CRS). This type of information is typically stored within the ".prj" component of a shapefile, or in the header of a GeoTiff. Without a CRS it is not possible to perform coordinate transformations (e.g. conversion of geographic coordinates to projected coordinates), spatial overlay (e.g. intersection), or geometric calculations (e.g. distance or area).

In R, CRS information is encoded using ["proj4" notation](http://proj4.org/), which looks something like this: `'+proj=longlat +datum=WGS84'` (geographic coordinates referened to the WGS84 datum). You can look-up CRS definitions in many different formats on the [spatialreference.org](http://spatialreference.org/) website. Some examples:

 * `+proj=longlat +datum=NAD83`: geographic coordinate system, NAD83 datum
 * `+proj=longlat +datum=NAD27`: geographic coordinate system, NAD27 datum
 * `+proj=utm +zone=10 +datum=NAD83`: projected coordinate system (UTM zone 10), NAD83 datum
 * `+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m`: AEA CONUS


Returning to the example from above, lets **assign** a CRS to this point using the `proj4string()` function. Note that this process doesn't alter the geometry of the object.
```{r }
proj4string(p) <- '+proj=longlat +datum=WGS84' 
str(p)
```

Transformation of points, lines, and polygons is a simple matter--as long the source and destination CRS data are available.
```{r}
# transform to UTM zone 14
p.utm <- spTransform(p, CRS('+proj=utm +zone=14 +datum=NAD83'))
cbind(gcs=coordinates(p), utm=coordinates(p.utm))

# transform to GCS NAD27
p.nad27 <- spTransform(p, CRS('+proj=longlat +datum=NAD27'))
cbind(coordinates(p), coordinates(p.nad27))
```

CRS definitions can also be generated from [EPSG](http://epsg.io/) codes. For example, a geographic coordinate system referenced to the WGS84 datum can be accessed using EPSG code 4326:
```{r}
CRS('+init=epsg:4326')
```


## Accessing Spatial Data Sources via GDAL/OGR
Many of the vector data sources we use can be directly translated to `sp` class objects via `rgdal` package. The `rgdal` package provides linkages to the powerful [GDAL/OGR](http://www.gdal.org/) library, the details of which are well beyond the scope of this training. Suffice to say, `rgdal` makes it possible to import just about any vector or raster data using two basic functions:

 * `readOGR()`: vector data sources such as shapefiles, KML, etc.
 * `readGDAL()`: raster data sources such as GeoTiff, IMG, ArcGRID, ASCII grids, etc.
 
A full listing of available drivers can be accessed with `ogrDrivers()` and `gdalDrivers()`. Note that it is not yet possible to load raster data from an ESRI File Geodatabase.

This module will not cover importing or exporting raster data via `rgdal` as the `raster` package provides a much more convenient interface to the GDAL library.


### Importing / Exporting Vector Data
In order to accommodate a wide range of possible formats, the `readOGR()` and `writeOGR()` functions expect a specialized description of the data source. 

Import the `ca630_a` feature class from a ESRI File Geodatabase:
```{r eval=FALSE}
x <- readOGR(dsn='E:/gis_data/ca630/FG_CA630_OFFICIAL.gdb', layer='ca630_a')
```

Import data from shapefile stored at `E:/gis_data/ca630/pedon_locations.shp`. Note that the trailing "/" is ommitted from the `dsn` (data source name) and the ".shp" suffix is ommitted from the `layer`.
```{r eval=FALSE}
x <- readOGR(dsn='E:/gis_data/ca630', layer='pedon_locations')
```

Export object `x` to shapefile. Note that the trailing "/" is ommitted from the `dsn` (data source name) and the ".shp" suffix is ommitted from the `layer`.
```{r eval=FALSE}
writeOGR(x, dsn='E:/gis_data/ca630', layer='pedon_locations', driver = 'ESRI Shapefile')
```

The `readOGR()` and `writeOGR()` functions have many arguments and format-specific details. It is worth spending some time with the associated manual pages.


### Things to Keep in Mind

 * `sp` class objects are memory-bound, you won't likely be able to load the full gSSURGO grid any time soon
 * operations on `sp` class objects (e.g. CRS transformations) are relatively slow
    + this isn't a problem unless you are working with 100k+ features
    + much of the functionality in the `sp` package is being re-imagined as part of the `sf` package, it is likely much more efficient
 * it is not possible to efficiently "warp" raster data stored in `sp` class objects
    + usually much faster warp raster data via GDAL command line tools (`gdalUtils` package) or GIS



## The `raster` Package
The release of the [`raster` package](https://cran.r-project.org/web/packages/raster/index.html) was a transformative event for scientists working with spatial data in R because of the unique way in which `RasterLayer` objects can be accessed *on-disk*. Previously, most of the available data structures (e.g. `SpatialGridDataFrame`, `SpatialPixelsDataFrame`, `matrix`, etc.) for storing raster data were memory-bound and not efficient for very large (> 10,000 x 10,000 cells) grids. That said, these data structures are still very useful for collections of raster data that fit into available memory. Many packages that perform advanced spatial analysis (e.g. `gstat` and `spatstat` packages) rely on the older data structures.

A more complete background on the capabilities of the `raster` package are described in the [*Introduction to the raster package*](https://cran.r-project.org/web/packages/raster/vignettes/Raster.pdf) vignette and recently released [*Spatial Data Analysis and Modeling with R*](http://rspatial.org/) online book.


### Importing / Exporting Data

Importing data is a simple matter. Note that the object `r` is a reference to the file.
```{r fig.width=6, fig.height=6}
# use an example from the raster package
f <- system.file("external/test.grd", package="raster")
# create a reference to this raster
r <- raster(f)
# print the details
print(r)
# default plot method
plot(r)
```

The disk-based reference can be converted to an in-memory `RasterLayer` with the `readAll()` function. Processing of raster data in memory is always faster than processing on disk, as long as there is sufficient memory.
```{r}
# check: file is on disk
inMemory(r)
# load into memory, if possible
r <- readAll(r)
# check: file is in memory
inMemory(r)
```


Exporting data requires consideration of the output format, datatype, encoding of NODATA, and other options such as compression. See the manual pages for `writeRaster()`, `writeFormats()`, and `dataType()` for details. For example, suppose you had a `RasterLayer` object that you wanted to save to disk as an internaly-compressed GeoTiff:
```{r eval=FALSE}
# using previous example data set
writeRaster(r, filename='r.tif', options=c("COMPRESS=LZW"))
```

The `writeRaster()` function interprets the given (and missing) arguments as:

  * '.tif' suffix interpreted as `format=GTiff`
  * creation options of "LZW compression" passed to GeoTiff driver
  * default `datatype`
  * default `NAflag`

#### Data Types
It is worth spending a couple minutes going over some the commonly used `datatypes`; "unsigned integer", " signed integer", and "floating point" of variable precision.

 * `INT1U`: integers from 0 to 255
 * `INT2U`: integers from 0 to 65,534
 * `INT2S`: integers from -32,767 to 32,767
 * `INT4S`: integers from -2,147,483,647 to 2,147,483,647
 * `FLT4S`: floating point from -3.4e+38 to 3.4e+38
 * `FLT8S`: floating point from -1.7e+308 to 1.7e+308

It is wise to manually specify an output `datatype` that will "just fit" the required precision. For exmaple, if you have generated a `RasterLayer` that warrants integer precision and ranges from 0 to 100, then the `INT1U` data type would provide enough precision to store all possible values *and* the NODATA value. Raster data stored as integers will always be smaller (sometimes 10-100x) than floating point, especially when internall compression is enabled.


### Object Properties
`RasterLayer` objects similar to `sp` objects in that they keep track of the linkages between data, coordinate reference system, and optional attribute tables. Getting and setting the contents of `RasterLayer` objects should be performed using functions such as:
  
  * `NAvalue(r)`: get / set the NODATA value
  * `crs(r)` or `proj4string(r)`: get / set the coordinate reference system
  * `res(r)`: get / set the resolution
  * `extent(r)`: get / set the extent
  * `dataType(r)`: get / set the data type
  * ... many more, see the `raster` package manual


### Things to Keep in Mind
  * the `raster` package provides data structures for working with grids either in memory or on disk
    + this enables relatively fast processing of small grids and reasonable processing of large grids
  * the `raster` package provides functions for performing most types of grid-based analysis
    + this is very convenient when working with small grids (no need to switch to GIS)
    + raster operations on large grids will always be faster with a dedicated GIS or GDAL tools
  * time spent with the `raster` [documentation](http://rspatial.org/) is well invested


# Intermission

If you haven't yet done so, please setup the sample datasets for this module.
```{r, eval=FALSE}
# store path as a variable, in case you want to keep it somewhere else
ch2b.data.path <- 'C:/workspace/chapter-2b'
# make a place to store chapter 2b example data
dir.create(ch2b.data.path, recursive = TRUE)

# download example data from github
# polygons
download.file('https://github.com/ncss-tech/stats_for_soil_survey/raw/master/data/chapter_2b-spatial-data/chapter-2b-mu-polygons.zip', paste0(ch2b.data.path, '/chapter-2b-mu-polygons.zip'))

# raster data
download.file('https://github.com/ncss-tech/stats_for_soil_survey/raw/master/data/chapter_2b-spatial-data/chapter-2b-PRISM.zip', paste0(ch2b.data.path, '/chapter-2b-PRISM.zip'))

# unzip
unzip(paste0(ch2b.data.path, '/chapter-2b-mu-polygons.zip'), exdir = ch2b.data.path, overwrite = TRUE)
unzip(paste0(ch2b.data.path, '/chapter-2b-PRISM.zip'), exdir = ch2b.data.path, overwrite = TRUE)
```



# Working With Real Data






Load some of the chapter 2 sample data for a simple demonstration of the `SpatialPolyhonsDataFrame` class.
```{r eval=FALSE}
mlra <- readOGR(dsn='C:/workspace/chapter-2b')

```



## Vector Data

## Raster Data


# Example: Generating Sampling Points



# Example: Extracting Spatial Data at NASIS Pedon Locations


# Example: Summarizing PRISM Data by MLRA



# Further Examples on the AQP Website
  * [SDA](http://ncss-tech.github.io/AQP/soilDB/SDA-tutorial.html)
  * [Export pedons to Google Earth](http://ncss-tech.github.io/AQP/soilDB/export-points-from-NASIS-to-Google-Earth.html)
  * [Export NASIS pedons to SHP](http://ncss-tech.github.io/AQP/soilDB/export-points-from-NASIS.html)
  * [Series extent mapping](http://ncss-tech.github.io/AQP/soilDB/series-extent.html)
 



The standard projection for point data in NASIS and Web Soil Survey is now long/lat WGS84 (i.e., EPSG code 4326). This is a geographic coordinate system. It projects the Earth as a sphere and measures distances in decimal degrees. Many spatial operations are necessary to use a projected coordinate system, which projects the Earth as a flat surface and measures distances in meters. All projected coordinate systems distort the Earth's surface to some degree. Within the continental U.S., a good choice is the USA Contiguous Albers Equal Area Conic USGS projection, which corresponds with EPSG code 5070.


# Extracting Spatial Data

When using soil survey data, you're typically interested in the values for spatial data that overlap point locations or polygons. This gives you information on the geomorphic setting of soil observations. You can then use this information to make predictions about the spatial distribution of soil properties or classes at unobserved sites (e.g., raster cells). The procedure for extracting spatial data at point locations is a simple process of intersecting the point coordinates with the spatial data and recording their values. This can be accomplished with almost any GIS program, including R.

Before you can extract spatial data for the purpose of spatial prediction, the data must meet the following conditions:  

 - All data conforms to a common projection and datum,
 - All raster data have a common cell resolution, and
 - All raster data are co-registered, that is, the geographic coordinates of cell centers are the same for all layers. Setting the _Snap Raster_ in the ArcGIS Processing Environment prior to the creation of raster derivatives can ensure cell alignment. An ERDAS model is also available to perform this task.  


## R Tools for Extracting Spatial Data

To extract point data using R, you can use either the `sp` or `raster` packages. For large raster data sets, it is best to use the `extract()` function from the raster package.

The following example takes pedon data locations from the CA794 soil survey, filters out pedons that are missing coordinates, and creates a `SpatialPointsDataFrame` object.  Rasters of 30-m elevation and slope are then imported and stacked. The `extract()` function is used to intersect the raster values at the pedon point locations.


# Exercise: Extracting Spatial Data

Using your own point data, extract the raster values for several pedons.

Submit the results to your coach.


# ArcGIS Tools for Extracting Spatial Data: Extracting Point Data from a Raster

This section discusses the use of the "Extract Multi Values to Points" tool, which assigns the cell value of specified raster data sets to existing points. The "Extract Values to Points" and "Sample" tools achieve similar results. These tools are described in the ESRI help section [An Overview of the Extraction Tools](http://help.arcgis.com/en/arcgisdesktop/10.0/help/index.html#/An_overview_of_the_Extraction_tools/009z00000028000000/).  

To start, assume you have 50 observations across an area of interest in an ArcGIS point file that has numerous observed soil properties. In your analysis, you will also consider such variables as slope, profile curvature, solar insolation, topographic wetness index, relative position, and elevation.
 
The Extract Multi Values to Points tool is the most expedient way to populate raster values to a point file. If your spatial extent is large and you have many raster layers; e.g., 12, it may be best to proceed using 3 or 4 rasters at a time and running the tool 3 or 4 times.  

The **Extract Multi Values to Points** tool is in the **Extraction** tool box in **Spatial Analyst Tools.**  

![R GUI image](figure/ch2_fig3.jpg)  

Select your point file and the associated raster files of interest as noted in the following graphic.  

![R GUI image](figure/ch2_fig4.jpg)  

The resulting point file has the corresponding cell values for slope, profile curvature, and wetness index attached to the point file as columns in the shapefile table.  

![R GUI image](figure/ch2_fig5.jpg)  

The resulting point file may also be saved as a text file for use in R.


# Additional Reading

Brenning, A., and D. Bangs. 2015. Introduction to terrain analysis with RSAGA: Landslide susceptibility modeling. [https://cran.r-project.org/web/packages/RSAGA/vignettes/RSAGA-landslides.pdf](https://cran.r-project.org/web/packages/RSAGA/vignettes/RSAGA-landslides.pdf).

Hijmans, R.J. 2015. Introduction to the 'raster' package. [https://cran.r-project.org/web/packages/raster/vignettes/Raster.pdf](https://cran.r-project.org/web/packages/raster/vignettes/Raster.pdf).

Pebesma, E., and R.S. Bivand. 2005. Classes and methods for spatial data: The sp package. [https://cran.r-project.org/web/packages/sp/vignettes/intro_sp.pdf](https://cran.r-project.org/web/packages/sp/vignettes/intro_sp.pdf).

Venables, W.N., D.M. Smith, and the R Core Team, 2015. Introduction to R, Notes on R: A programming environment for data analysis and graphics, version (3.2.3, 2015-12-10). [https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf](https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf).

Wickham, H. 2014. Advanced R. CRC Press, New York. [http://adv-r.had.co.nz/](http://adv-r.had.co.nz/).
